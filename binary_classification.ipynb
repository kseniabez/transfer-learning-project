{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be49b13c",
   "metadata": {},
   "source": [
    "# Basic Project: Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T11:50:16.627531Z",
     "start_time": "2025-05-02T11:50:16.623822Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import random_split\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "import numpy as np\n",
    "from torchvision.transforms import RandAugment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9428c9",
   "metadata": {},
   "source": [
    "Tic() Toc() Functions to track training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "c7462599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tic():\n",
    "    global startTime_for_tictoc\n",
    "    startTime_for_tictoc = time.time()\n",
    "\n",
    "def toc():\n",
    "    if 'startTime_for_tictoc' in globals():\n",
    "        return time.time() - startTime_for_tictoc\n",
    "        #print(\"Elapsed time is \" + str(time.time() - startTime_for_tictoc) + \" seconds.\")\n",
    "    else:\n",
    "        print(\"Toc: start time not set\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "b7d07f735d6ce8d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T11:50:26.163270Z",
     "start_time": "2025-05-02T11:50:26.159291Z"
    }
   },
   "outputs": [],
   "source": [
    "data_root = \"datasets\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccef44fd",
   "metadata": {},
   "source": [
    "Download ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "d822d2ee3a2ca1aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T11:50:28.100014Z",
     "start_time": "2025-05-02T11:50:28.092453Z"
    }
   },
   "outputs": [],
   "source": [
    "# for ResNet18:\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613107a2",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "666abda14682e0ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T11:50:29.995502Z",
     "start_time": "2025-05-02T11:50:29.959823Z"
    }
   },
   "outputs": [],
   "source": [
    "trainval_data = datasets.OxfordIIITPet(\n",
    "        root=data_root,\n",
    "        split='trainval',\n",
    "        target_types='binary-category',\n",
    "        transform=transform,\n",
    "        download=False\n",
    "    )\n",
    "test_data = datasets.OxfordIIITPet(\n",
    "        root=data_root,\n",
    "        split='test',\n",
    "        target_types='binary-category',\n",
    "        transform=transform,\n",
    "        download=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f852f9",
   "metadata": {},
   "source": [
    "Train / Test Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "4c91e21781a76757",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T11:50:31.831977Z",
     "start_time": "2025-05-02T11:50:31.824990Z"
    }
   },
   "outputs": [],
   "source": [
    "val_ratio = 0.2  # 20% for validation\n",
    "train_size = int((1 - val_ratio) * len(trainval_data))\n",
    "val_size = len(trainval_data) - train_size\n",
    "\n",
    "train_data, val_data = random_split(trainval_data, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "d5da3fd74362f472",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T11:50:34.049178Z",
     "start_time": "2025-05-02T11:50:34.043776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(736, 2944, 3669)"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data), len(train_data), len(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5816e8f8",
   "metadata": {},
   "source": [
    "Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "b6981347e5d5a52d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T11:50:39.097131Z",
     "start_time": "2025-05-02T11:50:39.090121Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "41503d58af5b6db2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T11:50:53.783971Z",
     "start_time": "2025-05-02T11:50:53.779321Z"
    }
   },
   "outputs": [],
   "source": [
    "dataloaders = {}\n",
    "dataset_sizes = {}\n",
    "\n",
    "dataloaders['train'] = train_loader\n",
    "dataloaders['val'] = val_loader\n",
    "dataloaders['test'] = test_loader\n",
    "\n",
    "dataset_sizes['train'] = len(train_data)\n",
    "dataset_sizes['val'] = len(val_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf33cf94",
   "metadata": {},
   "source": [
    "Initialize the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "72b91a7187a97c07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T11:50:55.634513Z",
     "start_time": "2025-05-02T11:50:55.446129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cpu':\n",
    "    print(\"If GPU is available: \\npip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "    print(\"Restart the kernel and run the code again.\")\n",
    "    print(\"Check with `print(torch.cuda.is_available())`\")\n",
    "    print(\"Documentation: https://pytorch.org/get-started/locally/\")\n",
    "    \n",
    "# ResNet18\n",
    "network = models.resnet18(weights='DEFAULT')\n",
    "nf = network.fc.in_features\n",
    "network.fc = nn.Linear(nf, 2)\n",
    "network = network.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeff8116",
   "metadata": {},
   "source": [
    "Function to Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "d5dcf515323571c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T12:08:02.047077Z",
     "start_time": "2025-05-02T12:08:02.038085Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_network(network, dataloaders, dataset_sizes, criterion, optimizer, num_epochs=25):\n",
    "\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    # Set Starting Time\n",
    "    tic()\n",
    "\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_network_params_path = os.path.join(tempdir, 'best_network_params.pt')\n",
    "\n",
    "        torch.save(network.state_dict(), best_network_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    network.train()\n",
    "                else:\n",
    "                    network.eval()\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                for X, Y in dataloaders[phase]:\n",
    "                    X = X.to(device)\n",
    "                    Y = Y.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        S = network(X)\n",
    "                        _, P = torch.max(S, 1)\n",
    "                        loss = criterion(S, Y)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * X.size(0)\n",
    "                    running_corrects += torch.sum(P == Y.data)\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                if phase == 'train':\n",
    "                    train_losses.append(epoch_loss)\n",
    "                    train_accuracies.append(epoch_acc.item())\n",
    "                else:\n",
    "                    val_losses.append(epoch_loss)\n",
    "                    val_accuracies.append(epoch_acc.item())\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(network.state_dict(), best_network_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        network.load_state_dict(torch.load(best_network_params_path, weights_only=True))\n",
    "        \n",
    "    # Print Time for Training only\n",
    "    el_time_training = toc()\n",
    "    print(f\"\\nTime for training: {el_time_training:.1f} sec.\")\n",
    "    \n",
    "    # Return Network and Training Statistics\n",
    "    train_stats = {\n",
    "        'train_losses': train_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_losses': val_losses,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'elapsed_time': el_time_training,\n",
    "    }\n",
    "    \n",
    "    return network, train_stats\n",
    "    # return network, train_losses, val_losses, train_accuracies, val_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "c12c171e7ac4cab0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T12:08:27.126364Z",
     "start_time": "2025-05-02T12:08:27.121461Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(network, loader, print_result=True):\n",
    "    network.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, Y in loader:\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            S = network(X)\n",
    "            _, P = torch.max(S, 1)\n",
    "            correct += (P == Y).sum().item()\n",
    "            total += Y.size(0)\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    if print_result:\n",
    "        print(f\"Test Accuracy: {acc:.2f}%\")\n",
    "        \n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1698ab4",
   "metadata": {},
   "source": [
    "Define Entropy Criterion and the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "98d21dbcfa1a6a8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T12:08:28.552107Z",
     "start_time": "2025-05-02T12:08:28.546457Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(network.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8828229",
   "metadata": {},
   "source": [
    "Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "11eb39d6f2d80808",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T12:19:22.161337Z",
     "start_time": "2025-05-02T12:08:36.603934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Running for 25 epochs\n",
    "TrainYN = False\n",
    "if TrainYN:\n",
    "    network, train_stats = train_network(\n",
    "        network, dataloaders, dataset_sizes, criterion, optimizer, num_epochs=25\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bd0e1f",
   "metadata": {},
   "source": [
    "Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "f41b5c7346cd86a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T12:43:48.473953Z",
     "start_time": "2025-05-02T12:43:48.255739Z"
    }
   },
   "outputs": [],
   "source": [
    "def VisLossAccuracy(train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "\n",
    "    plt.figure(facecolor='white', figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss over epochs')\n",
    "    plt.grid()\n",
    "    #plt.show()\n",
    "\n",
    "    #plt.figure(facecolor='white')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    #plt.ylim([0.9, 1.02])\n",
    "    plt.title('Accuracy over epochs')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# Visualize the loss and accuracy of the Network\n",
    "if TrainYN:    \n",
    "    train_losses, val_losses, train_accuracies, val_accuracies = \\\n",
    "                train_stats['train_losses'], train_stats['val_losses'], \\\n",
    "                train_stats['train_accuracies'], train_stats['val_accuracies']  \n",
    "    VisLossAccuracy(train_losses, val_losses, train_accuracies, val_accuracies)\n",
    "    compute_accuracy(network, test_loader)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e6e003",
   "metadata": {},
   "source": [
    "## Multi-Class Problem\n",
    "- Identifying all 37 breeds of Cats & Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "c5835050d7c3d976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_TrainTestData(data_root, target_types, transform):\n",
    "    trainval_data = datasets.OxfordIIITPet(\n",
    "        root=data_root,\n",
    "        split='trainval',\n",
    "        target_types=target_types,\n",
    "        transform=transform,\n",
    "        download=False\n",
    "    )\n",
    "    test_data = datasets.OxfordIIITPet(\n",
    "        root=data_root,\n",
    "        split='test',\n",
    "        target_types=target_types,\n",
    "        transform=transform,\n",
    "        download=False\n",
    "    )\n",
    "\n",
    "    val_ratio = 0.2  # 20% for validation\n",
    "    train_size = int((1 - val_ratio) * len(trainval_data))\n",
    "    val_size = len(trainval_data) - train_size\n",
    "\n",
    "    train_data, val_data = random_split(trainval_data, [train_size, val_size])\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "\n",
    "def DataLoaderFnc(train_data, val_data, test_data, batch_size=32):\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    dataloaders = {}\n",
    "    dataset_sizes = {}\n",
    "\n",
    "    dataloaders['train'] = train_loader\n",
    "    dataloaders['val'] = val_loader\n",
    "    dataloaders['test'] = test_loader\n",
    "\n",
    "    dataset_sizes['train'] = len(train_data)\n",
    "    dataset_sizes['val'] = len(val_data)\n",
    "\n",
    "    return dataloaders, dataset_sizes\n",
    "\n",
    "\n",
    "def Initialize_ResNet18(no_target_classes=2):\n",
    "    \n",
    "    network = models.resnet18(weights='DEFAULT')\n",
    "    nf = network.fc.in_features\n",
    "    network.fc = nn.Linear(nf, no_target_classes)\n",
    "    network = network.to(device)\n",
    "    \n",
    "    return network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "c03be1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainYN = False\n",
    "if TrainYN:\n",
    "    \n",
    "    # Load Train, Validation and Test Data\n",
    "    train_data, val_data, test_data = Load_TrainTestData(data_root, 'category', transform)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    dataloaders, dataset_sizes = DataLoaderFnc(train_data, val_data, test_data, batch_size=32)\n",
    "\n",
    "    # Initialize ResNet18\n",
    "    init_network = Initialize_ResNet18(no_target_classes=37)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(init_network.parameters(), lr=1e-4)\n",
    "\n",
    "    # Train the network\n",
    "    network, train_stats = train_network(\n",
    "        init_network, dataloaders, dataset_sizes, criterion, optimizer, num_epochs=10\n",
    "    )\n",
    "\n",
    "    # Visualize the loss and accuracy of the Network\n",
    "    train_losses, val_losses, train_accuracies, val_accuracies = \\\n",
    "                train_stats['train_losses'], train_stats['val_losses'], \\\n",
    "                train_stats['train_accuracies'], train_stats['val_accuracies']\n",
    "    VisLossAccuracy(train_losses, val_losses, train_accuracies, val_accuracies)\n",
    "\n",
    "    # Print the Accuracy\n",
    "    final_acc = compute_accuracy(network, test_loader, print_result=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3153c621",
   "metadata": {},
   "source": [
    "Build one big Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "97372441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainResNet18_S1(data_root, target_types, transform, TrainParams):\n",
    "    \n",
    "    # Extract Training Parameters\n",
    "    batch_size = TrainParams.get('batch_size', 32)\n",
    "    num_epochs = TrainParams.get('num_epochs', 25)\n",
    "    no_target_classes = TrainParams.get('no_target_classes', 2)\n",
    "    lr = TrainParams.get('lr', 1e-4)\n",
    "    L = TrainParams.get('L', 0)  # Number of layers to fine-tune simultaneously\n",
    "    strategy = TrainParams['strategy']  # 'fine-tune' or 'un-freeze'\n",
    "    curr_layer = TrainParams.get('curr_layer', 0)  # Current layer to unfreeze\n",
    "    InitNetYN = TrainParams.get('InitNetYN', True)  # Initialize network\n",
    "    \n",
    "    # Load Train, Validation and Test Data\n",
    "    train_data, val_data, test_data = Load_TrainTestData(data_root, target_types, transform)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    dataloaders, dataset_sizes = DataLoaderFnc(train_data, val_data, test_data, batch_size)\n",
    "\n",
    "    # Initialize ResNet18\n",
    "    init_network = Initialize_ResNet18(no_target_classes)\n",
    "    \n",
    "    # Freeze/Unfreeze Layers\n",
    "    if strategy == 'fine-tune':\n",
    "        for l, param in enumerate(init_network.parameters()):\n",
    "            if l <= L:\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "    elif strategy == 'un-freeze':\n",
    "        for l, param in enumerate(init_network.parameters()):\n",
    "            param.requires_grad = False\n",
    "            if l == curr_layer:\n",
    "                param.requires_grad = True\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(init_network.parameters(), lr)\n",
    "\n",
    "    # Train the network\n",
    "    network, train_stats = train_network(\n",
    "        init_network, dataloaders, dataset_sizes, criterion, optimizer, num_epochs\n",
    "    )\n",
    "\n",
    "    # Visualize the loss and accuracy of the Network\n",
    "    train_losses, val_losses, train_accuracies, val_accuracies = \\\n",
    "                train_stats['train_losses'], train_stats['val_losses'], \\\n",
    "                train_stats['train_accuracies'], train_stats['val_accuracies']  \n",
    "    VisLossAccuracy(train_losses, val_losses, train_accuracies, val_accuracies)\n",
    "\n",
    "    # Print the Accuracy\n",
    "    final_acc = compute_accuracy(network, test_loader, print_result=True)\n",
    "\n",
    "    # Add the final accuracy to the training statistics\n",
    "    train_stats['final_accuracy'] = final_acc\n",
    "    \n",
    "    return network, train_stats\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1ae48a",
   "metadata": {},
   "source": [
    "### Strategy 1: Fine-tune $l$ layers simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "08d49cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers to unfreeze\n",
    "layers = [0, 3, 5, 10]\n",
    "\n",
    "# Training Parameters\n",
    "TrainParams = {\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 10,\n",
    "    'no_target_classes': 37,\n",
    "    'lr': 1e-4,\n",
    "    'L': 0,  # Unfreeze the last layer\n",
    "    'strategy': 'fine-tune',  # 'fine-tune' or 'un-freeze'\n",
    "}\n",
    "\n",
    "\n",
    "# Loop through the layers and train the network\n",
    "train_stats_list = []\n",
    "TrainYN = False\n",
    "if TrainYN:\n",
    "    for l in layers:\n",
    "        print(f\"\\nTraining with fine-tuning layers up to layer {l}...\")\n",
    "        TrainParams['L'] = l  # Set the number of layers to fine-tune\n",
    "        _, train_stats_S1 = TrainResNet18_S1(data_root, 'category', transform, TrainParams)\n",
    "        print(f\"Finished training with fine-tuning layers up to layer {l}.\")\n",
    "        train_stats_list.append(train_stats)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38908dd3",
   "metadata": {},
   "source": [
    "### Strategy 2: Gradual un-freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "26eb7e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainResNet18_S2(data_root, target_types, transform, TrainParams):\n",
    "    \n",
    "    # Extract Training Parameters\n",
    "    batch_size = TrainParams.get('batch_size', 32)\n",
    "    num_epochs = TrainParams.get('num_epochs', 25)\n",
    "    no_target_classes = TrainParams.get('no_target_classes', 2)\n",
    "    lr = TrainParams.get('lr', 1e-4)\n",
    "    \n",
    "    # Load Train, Validation and Test Data\n",
    "    train_data, val_data, test_data = Load_TrainTestData(data_root, target_types, transform)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    dataloaders, dataset_sizes = DataLoaderFnc(train_data, val_data, test_data, batch_size)\n",
    "\n",
    "    # Initialize ResNet18\n",
    "    init_network = Initialize_ResNet18(no_target_classes)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(init_network.parameters(), lr)\n",
    "    \n",
    "    # Freeze/Unfreeze Layers\n",
    "    network = init_network\n",
    "    list_train_stats = []\n",
    "    print(\"\\nStart Training Network (Strategy: gradually unfreeze layers) ...\")\n",
    "    # Loop around the layers and train the network\n",
    "    for layer, _ in enumerate(init_network.parameters()):\n",
    "        # Freeze / unfreeze the right layers (gradually unfreeze)\n",
    "        for l, param in enumerate(network.parameters()):\n",
    "            param.requires_grad = False\n",
    "            if l == layer: # unfreeze the current layer\n",
    "                param.requires_grad = True\n",
    "        # Train the network (only the unfreezed layers)\n",
    "        print(\"------------------------------------------\")\n",
    "        print(f\"\\nTraining with unfreezing layer {layer}...\")\n",
    "        network, train_stats = train_network(\n",
    "            network, dataloaders, dataset_sizes, criterion, optimizer, num_epochs\n",
    "        )\n",
    "        list_train_stats.append(train_stats)\n",
    "\n",
    "\n",
    "    # Visualize the loss and accuracy of the Network\n",
    "    train_losses, val_losses, train_accuracies, val_accuracies = \\\n",
    "                train_stats['train_losses'], train_stats['val_losses'], \\\n",
    "                train_stats['train_accuracies'], train_stats['val_accuracies']  \n",
    "    VisLossAccuracy(train_losses, val_losses, train_accuracies, val_accuracies)\n",
    "\n",
    "    # Print the Accuracy\n",
    "    final_acc = compute_accuracy(network, test_loader, print_result=True)\n",
    "\n",
    "    # Add the final accuracy to the training statistics\n",
    "    train_stats['final_accuracy'] = final_acc\n",
    "    \n",
    "    return network, train_stats, list_train_stats\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "271931e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "TrainParams['strategy'] = 'un-freeze'\n",
    "\n",
    "# Train the network with gradually unfreezing layers\n",
    "TrainYN = False\n",
    "if TrainYN:\n",
    "    trained_net_S2, train_stats_S2, list_train_stats = TrainResNet18_S2(data_root, 'category', transform, TrainParams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a005a78",
   "metadata": {},
   "source": [
    "## Fine-Tuning with imbalanced classes\n",
    "- Check the Training behavior with class-imbalance\n",
    "- Try a strategy (e.g. weighted cross-entropy and/or over-sampling of minority classes) to compensate the imbalanced training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4e6146",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb795d37",
   "metadata": {},
   "source": [
    "# Extend basic project --> B/A\n",
    "- FixMatch\n",
    "- https://github.com/google-research/fixmatch/blob/master/pseudo_label.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d1fa5",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "- weak augmentation\n",
    "- strong augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "1968e180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strong_augmentation(image_size=224):\n",
    "    return transforms.Compose([\n",
    "        transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        RandAugment(num_ops=2, magnitude=10),  # Same idea: 2 operations, magnitude 10\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_weak_augmentation(image_size=224):\n",
    "    return transforms.Compose([\n",
    "        transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Imagenet normalization\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "class TransformFixMatch:\n",
    "    \"\"\"Applies weak and strong augmentation to the same input image.\"\"\"\n",
    "    def __init__(self, image_size=224):\n",
    "        self.weak = get_weak_augmentation(image_size)\n",
    "        self.strong = get_strong_augmentation(image_size)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        weak_aug = self.weak(x)\n",
    "        strong_aug = self.strong(x)\n",
    "        print(f\"Weak Augmentation: {weak_aug.shape}, Strong Augmentation: {strong_aug.shape}\")\n",
    "        return weak_aug, strong_aug\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bce4734",
   "metadata": {},
   "source": [
    "### Perpare the Dataset\n",
    "- Split labelled / unlabelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77c5661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_labeled_unlabeled(dataset, num_labels_per_class, num_classes):\n",
    "    \n",
    "    #targets = np.array(dataset.targets)\n",
    "    targets = np.array([dataset[i][1] for i in range(len(dataset))])  # Access the second element (label) of each sample\n",
    "    labeled_indices = []\n",
    "    unlabeled_indices = []\n",
    "    \n",
    "    for class_idx in range(num_classes):\n",
    "        class_indices = np.where(targets == class_idx)[0]\n",
    "        np.random.shuffle(class_indices)\n",
    "        \n",
    "        # Select the first num_labels_per_class indices for labeled data\n",
    "        labeled_indices.extend(class_indices[:num_labels_per_class])\n",
    "        unlabeled_indices.extend(class_indices[num_labels_per_class:])\n",
    "        \n",
    "    return labeled_indices, unlabeled_indices\n",
    "\n",
    "\n",
    "def load_train_val_test_data(data_root, target_types, transform, num_labels_per_class, num_classes, batch_size_labeld=32, batch_size_unlabeld=64, image_size=224):\n",
    "    # Common normalization values for ImageNet (can fine-tune later)\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                      std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "    # Define transforms\n",
    "    weak_transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "\n",
    "    strong_transform = TransformFixMatch(image_size)  # RandAugment included\n",
    "    val_test_transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "        \n",
    "    \n",
    "    # Load the full dataset\n",
    "    full_dataset = datasets.OxfordIIITPet(\n",
    "        root=data_root,\n",
    "        split='trainval',\n",
    "        target_types=target_types,\n",
    "        transform=transform,\n",
    "        download=False\n",
    "    )\n",
    "    \n",
    "    test_dataset = datasets.OxfordIIITPet(\n",
    "        root=data_root,\n",
    "        split='test',\n",
    "        target_types=target_types,\n",
    "        transform=val_test_transform,\n",
    "        download=False\n",
    "    )\n",
    "    \n",
    "    # Split into labeled and unlabeled data\n",
    "    labeled_indices, unlabeled_indices = split_labeled_unlabeled(full_dataset, num_labels_per_class, num_classes)\n",
    "    \n",
    "    # Create labeled and unlabeled datasets\n",
    "    labeled_dataset = Subset(full_dataset, labeled_indices)\n",
    "    unlabeled_dataset = Subset(full_dataset, unlabeled_indices)\n",
    "    \n",
    "    # Apply transforms\n",
    "    print(f\"Unlabeled dataset transform: {unlabeled_dataset.dataset.transform}\")\n",
    "    labeled_dataset.dataset.transform = weak_transform\n",
    "    unlabeled_dataset.dataset.transform = strong_transform\n",
    "    \n",
    "    # Optional: make a validation split out of labeled set\n",
    "    val_ratio = 0.2\n",
    "    val_size = int(val_ratio * len(labeled_dataset))\n",
    "    train_size = len(labeled_dataset) - val_size\n",
    "    labeled_dataset, val_dataset = random_split(labeled_dataset, [train_size, val_size])\n",
    "    \n",
    "    # Dictionary to hold DataLoaders\n",
    "    dataloaders = {\n",
    "        'labeled': DataLoader(labeled_dataset, batch_size=batch_size_labeld, shuffle=True),\n",
    "        'unlabeled': DataLoader(unlabeled_dataset, batch_size=batch_size_unlabeld, shuffle=True),\n",
    "        'val': DataLoader(val_dataset, batch_size=batch_size_labeld, shuffle=False),\n",
    "        'test': DataLoader(test_dataset, batch_size=batch_size_labeld, shuffle=False)\n",
    "    }\n",
    "    \n",
    "    return dataloaders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9717f1",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "9025791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fixmatch_loss(logits_x, targets_x, logits_u_w, logits_u_s, threshold=0.95, lambda_u=1.0):\n",
    "    \"\"\"\n",
    "    logits_x: model outputs for labeled data\n",
    "    targets_x: ground-truth labels for labeled data\n",
    "    logits_u_w: model outputs for weakly augmented unlabeled data\n",
    "    logits_u_s: model outputs for strongly augmented unlabeled data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Supervised loss\n",
    "    loss_x = nn.F.cross_entropy(logits_x, targets_x, reduction='mean')\n",
    "    \n",
    "    # Generate pseudo labels from weakly augmented unlabeled data\n",
    "    pseudo_labels = torch.softmax(logits_u_w, dim=-1)\n",
    "    max_probs, targets_u = torch.max(pseudo_labels, dim=-1)\n",
    "    \n",
    "    # Mask to select high-confidence pseudo-labels\n",
    "    mask = max_probs.ge(threshold).float()\n",
    "    \n",
    "    # Unsupervised loss (only for confident predictions)\n",
    "    loss_u = (nn.F.cross_entropy(logits_u_s, targets_u, reduction='none') * mask).mean()\n",
    "    \n",
    "    # Total loss\n",
    "    total_loss = loss_x + lambda_u * loss_u\n",
    "    \n",
    "    return total_loss, loss_x, loss_u\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a4d2e2",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "4a5fce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fixmatch(model, labeled_loader, unlabeled_loader, optimizer, device, epoch, lambda_u=1.0, threshold=0.95):\n",
    "    model.train()\n",
    "\n",
    "    # Track losses\n",
    "    running_loss = 0.0\n",
    "    running_supervised_loss = 0.0\n",
    "    running_unsupervised_loss = 0.0\n",
    "\n",
    "    unlabeled_iter = iter(unlabeled_loader)\n",
    "\n",
    "    for batch_idx, (inputs_x, targets_x) in enumerate(labeled_loader):\n",
    "        try:\n",
    "            # Correctly unpack the unlabeled data\n",
    "            unlabeled_batch = next(unlabeled_iter)\n",
    "            inputs_u, _ = unlabeled_batch  # Unpack images and ignore labels\n",
    "            print(f\"Unlabeled batch: {unlabeled_batch}\")\n",
    "            print(f\"Inputs_u: {inputs_u}\")\n",
    "            inputs_u_w, inputs_u_s = inputs_u  # Unpack weak and strong augmentations\n",
    "        except StopIteration:\n",
    "            unlabeled_iter = iter(unlabeled_loader)\n",
    "            unlabeled_batch = next(unlabeled_iter)\n",
    "            inputs_u, _ = unlabeled_batch\n",
    "            inputs_u_w, inputs_u_s = inputs_u\n",
    "\n",
    "        # Move data to device (GPU or CPU)\n",
    "        inputs_x, targets_x = inputs_x.to(device), targets_x.to(device)\n",
    "        inputs_u_w, inputs_u_s = inputs_u_w.to(device), inputs_u_s.to(device)\n",
    "\n",
    "        batch_size = inputs_x.size(0)\n",
    "\n",
    "        # Forward pass\n",
    "        logits_x = model(inputs_x)\n",
    "        logits_u_w = model(inputs_u_w)\n",
    "        logits_u_s = model(inputs_u_s)\n",
    "\n",
    "        # Compute FixMatch loss\n",
    "        total_loss, loss_x, loss_u = compute_fixmatch_loss(\n",
    "            logits_x, targets_x, logits_u_w, logits_u_s,\n",
    "            threshold=threshold, lambda_u=lambda_u\n",
    "        )\n",
    "\n",
    "        # Optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        running_loss += total_loss.item()\n",
    "        running_supervised_loss += loss_x.item()\n",
    "        running_unsupervised_loss += loss_u.item()\n",
    "\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f\"Epoch [{epoch}] Batch [{batch_idx}] \"\n",
    "                  f\"Loss: {total_loss.item():.4f} \"\n",
    "                  f\"Supervised Loss: {loss_x.item():.4f} \"\n",
    "                  f\"Unsupervised Loss: {loss_u.item():.4f}\")\n",
    "\n",
    "    epoch_loss = running_loss / len(labeled_loader)\n",
    "    epoch_supervised_loss = running_supervised_loss / len(labeled_loader)\n",
    "    epoch_unsupervised_loss = running_unsupervised_loss / len(labeled_loader)\n",
    "\n",
    "    return epoch_loss, epoch_supervised_loss, epoch_unsupervised_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf0c9c",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "ad75b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,5)):\n",
    "    \"\"\"Computes the top-k accuracy\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)  # Top-k predictions\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    top1_correct = 0\n",
    "    top5_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute top-k accuracies\n",
    "            top1, top5 = accuracy(outputs, targets, topk=(1, 5))\n",
    "            \n",
    "            top1_correct += top1.item() * inputs.size(0) / 100.0\n",
    "            top5_correct += top5.item() * inputs.size(0) / 100.0\n",
    "            total += inputs.size(0)\n",
    "    \n",
    "    top1_acc = 100.0 * top1_correct / total\n",
    "    top5_acc = 100.0 * top5_correct / total\n",
    "\n",
    "    print(f\"Validation Top-1 Accuracy: {top1_acc:.2f}% | Top-5 Accuracy: {top5_acc:.2f}%\")\n",
    "    \n",
    "    return top1_acc, top5_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c844ac87",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "b68c3ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef get_labeled_loader(batch_size=64, image_size=224, num_labels_per_class=100):\\n    # Load full dataset\\n    dataset = datasets.ImageFolder('path_to_your_labeled_data', \\n                                   transform=get_weak_augmentation(image_size))\\n\\n    # Subsample: only num_labels_per_class samples per class\\n    labels = np.array([label for _, label in dataset.imgs])\\n    labeled_idx = []\\n\\n    for c in np.unique(labels):\\n        idx_c = np.where(labels == c)[0]\\n        idx_c = np.random.choice(idx_c, num_labels_per_class, replace=False)\\n        labeled_idx.extend(idx_c)\\n\\n    labeled_dataset = Subset(dataset, labeled_idx)\\n\\n    labeled_loader = DataLoader(labeled_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\\n    return labeled_loader\\n\\n\\ndef get_unlabeled_loader(batch_size=320, image_size=224):\\n    # Load full unlabeled dataset\\n    dataset = datasets.ImageFolder('path_to_your_unlabeled_data', \\n                                   transform=TransformFixMatch(image_size))\\n\\n    unlabeled_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\\n    return unlabeled_loader\\n\\n\\ndef get_validation_loader(batch_size=64, image_size=224):\\n    # Validation set: no strong augmentation, only normalization\\n    transform_val = transforms.Compose([\\n        transforms.Resize((image_size, image_size)),\\n        transforms.ToTensor(),\\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\\n                             std=[0.229, 0.224, 0.225])\\n    ])\\n\\n    val_dataset = datasets.ImageFolder('path_to_your_validation_data', transform=transform_val)\\n\\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\\n    return val_loader\\n\""
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def get_labeled_loader(batch_size=64, image_size=224, num_labels_per_class=100):\n",
    "    # Load full dataset\n",
    "    dataset = datasets.ImageFolder('path_to_your_labeled_data', \n",
    "                                   transform=get_weak_augmentation(image_size))\n",
    "\n",
    "    # Subsample: only num_labels_per_class samples per class\n",
    "    labels = np.array([label for _, label in dataset.imgs])\n",
    "    labeled_idx = []\n",
    "\n",
    "    for c in np.unique(labels):\n",
    "        idx_c = np.where(labels == c)[0]\n",
    "        idx_c = np.random.choice(idx_c, num_labels_per_class, replace=False)\n",
    "        labeled_idx.extend(idx_c)\n",
    "\n",
    "    labeled_dataset = Subset(dataset, labeled_idx)\n",
    "\n",
    "    labeled_loader = DataLoader(labeled_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
    "    return labeled_loader\n",
    "\n",
    "\n",
    "def get_unlabeled_loader(batch_size=320, image_size=224):\n",
    "    # Load full unlabeled dataset\n",
    "    dataset = datasets.ImageFolder('path_to_your_unlabeled_data', \n",
    "                                   transform=TransformFixMatch(image_size))\n",
    "\n",
    "    unlabeled_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
    "    return unlabeled_loader\n",
    "\n",
    "\n",
    "def get_validation_loader(batch_size=64, image_size=224):\n",
    "    # Validation set: no strong augmentation, only normalization\n",
    "    transform_val = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_dataset = datasets.ImageFolder('path_to_your_validation_data', transform=transform_val)\n",
    "\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    return val_loader\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8371b72",
   "metadata": {},
   "source": [
    "### Full Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "c0ea491e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlabeled dataset transform: Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "Number of labeled samples: 1184\n",
      "Number of unlabeled samples: 2200\n",
      "Unlabeled loader batch size: 320\n",
      "\n",
      "--- Epoch 1/10 ---\n",
      "Unlabeled batch: [tensor([[[[-0.6109, -0.5938, -0.5938,  ..., -0.3198, -0.3027, -0.3198],\n",
      "          [-0.5938, -0.5938, -0.5767,  ..., -0.3027, -0.3198, -0.3369],\n",
      "          [-0.6452, -0.6452, -0.6623,  ..., -0.3198, -0.3198, -0.3369],\n",
      "          ...,\n",
      "          [ 0.2282,  0.3481,  0.2453,  ...,  1.4269,  1.4954,  1.5125],\n",
      "          [ 0.2624,  0.2796,  0.1939,  ...,  1.4269,  1.4783,  1.5468],\n",
      "          [ 0.2453,  0.2111,  0.1426,  ...,  1.5468,  1.6324,  1.6324]],\n",
      "\n",
      "         [[-0.4076, -0.4076, -0.3901,  ..., -0.5651, -0.5826, -0.5826],\n",
      "          [-0.4601, -0.4426, -0.4251,  ..., -0.5476, -0.5651, -0.5826],\n",
      "          [-0.4951, -0.4951, -0.5126,  ..., -0.5651, -0.5651, -0.5826],\n",
      "          ...,\n",
      "          [ 0.2227,  0.3102,  0.1877,  ...,  1.5882,  1.6408,  1.6408],\n",
      "          [ 0.2402,  0.2402,  0.1527,  ...,  1.5882,  1.6583,  1.6933],\n",
      "          [ 0.2052,  0.1702,  0.1001,  ...,  1.7108,  1.7983,  1.7983]],\n",
      "\n",
      "         [[-0.1835, -0.1661, -0.1661,  ..., -0.8458, -0.8458, -0.8284],\n",
      "          [-0.2358, -0.2358, -0.2184,  ..., -0.8284, -0.8284, -0.8284],\n",
      "          [-0.2881, -0.2881, -0.3055,  ..., -0.8110, -0.8110, -0.8284],\n",
      "          ...,\n",
      "          [ 0.3393,  0.4788,  0.3742,  ...,  1.8208,  1.8557,  1.8731],\n",
      "          [ 0.3742,  0.4091,  0.3393,  ...,  1.8208,  1.8731,  1.9254],\n",
      "          [ 0.3742,  0.3568,  0.2871,  ...,  1.9603,  2.0474,  2.0474]]],\n",
      "\n",
      "\n",
      "        [[[-1.9980, -1.9980, -2.0323,  ...,  1.1529,  1.1529,  1.1700],\n",
      "          [-1.9980, -1.9980, -2.0323,  ...,  1.1529,  1.1529,  1.1529],\n",
      "          [-1.9980, -1.9980, -2.0323,  ...,  1.1700,  1.1529,  1.1529],\n",
      "          ...,\n",
      "          [-2.0494, -2.0494, -2.0494,  ..., -1.2445, -1.2617, -1.2788],\n",
      "          [-2.0665, -2.0494, -2.0494,  ..., -1.3130, -1.3130, -1.3473],\n",
      "          [-2.0837, -2.1179, -2.0837,  ..., -1.5185, -1.4843, -1.4500]],\n",
      "\n",
      "         [[-2.0182, -2.0007, -1.9832,  ...,  0.3452,  0.3452,  0.3627],\n",
      "          [-2.0182, -2.0007, -1.9832,  ...,  0.3452,  0.3452,  0.3452],\n",
      "          [-2.0182, -1.9832, -1.9832,  ...,  0.3277,  0.3102,  0.3102],\n",
      "          ...,\n",
      "          [-1.9657, -1.9657, -1.9657,  ..., -1.4580, -1.4755, -1.4930],\n",
      "          [-1.9832, -1.9657, -1.9657,  ..., -1.4755, -1.4755, -1.5105],\n",
      "          [-2.0007, -2.0357, -2.0007,  ..., -1.6331, -1.5980, -1.5630]],\n",
      "\n",
      "         [[-1.7870, -1.7522, -1.7347,  ..., -0.8633, -0.8633, -0.8458],\n",
      "          [-1.7696, -1.7347, -1.7347,  ..., -0.8633, -0.8633, -0.8633],\n",
      "          [-1.7522, -1.7347, -1.7347,  ..., -0.8633, -0.8807, -0.8807],\n",
      "          ...,\n",
      "          [-1.7347, -1.7347, -1.7347,  ..., -1.2641, -1.2816, -1.2990],\n",
      "          [-1.7522, -1.7347, -1.7347,  ..., -1.2990, -1.2990, -1.3339],\n",
      "          [-1.7696, -1.8044, -1.7696,  ..., -1.4036, -1.3687, -1.3339]]],\n",
      "\n",
      "\n",
      "        [[[-1.3644, -1.3987, -1.2959,  ..., -0.5253, -0.4739, -0.4911],\n",
      "          [-1.3302, -1.3644, -1.2788,  ..., -0.4739, -0.4226, -0.4568],\n",
      "          [-1.2788, -1.2788, -1.2445,  ..., -0.4397, -0.3541, -0.3369],\n",
      "          ...,\n",
      "          [-0.7137, -0.6794, -0.6281,  ...,  0.6392,  0.6906,  0.7591],\n",
      "          [-0.6794, -0.6281, -0.6452,  ...,  0.7077,  0.6734,  0.7248],\n",
      "          [-0.6623, -0.5424, -0.6281,  ...,  0.7762,  0.7419,  0.7591]],\n",
      "\n",
      "         [[-1.6155, -1.5805, -1.5455,  ..., -0.6352, -0.6176, -0.6176],\n",
      "          [-1.6331, -1.5630, -1.5630,  ..., -0.6001, -0.6352, -0.6352],\n",
      "          [-1.6681, -1.6331, -1.5805,  ..., -0.6527, -0.6352, -0.6352],\n",
      "          ...,\n",
      "          [-1.4230, -1.4580, -1.4055,  ..., -0.1800, -0.1450, -0.0924],\n",
      "          [-1.4580, -1.4930, -1.4230,  ..., -0.1800, -0.1800, -0.1450],\n",
      "          [-1.5280, -1.4930, -1.4230,  ..., -0.1625, -0.1275, -0.1099]],\n",
      "\n",
      "         [[-1.4907, -1.5430, -1.5256,  ..., -0.5670, -0.5844, -0.5844],\n",
      "          [-1.4733, -1.5256, -1.5430,  ..., -0.6367, -0.5844, -0.6018],\n",
      "          [-1.5081, -1.5430, -1.5430,  ..., -0.6193, -0.5495, -0.5321],\n",
      "          ...,\n",
      "          [-1.5779, -1.5953, -1.5430,  ..., -0.5321, -0.5321, -0.4798],\n",
      "          [-1.5953, -1.5953, -1.5604,  ..., -0.5670, -0.6193, -0.5844],\n",
      "          [-1.6476, -1.5604, -1.5779,  ..., -0.5147, -0.5495, -0.5321]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.0837, -2.0323, -2.0494,  ..., -2.0665, -2.0665, -2.1008],\n",
      "          [-1.4843,  0.6049,  0.8104,  ...,  0.8276,  0.6049, -1.4672],\n",
      "          [-1.1932,  1.8037,  1.8379,  ...,  1.8722,  1.8037, -1.1932],\n",
      "          ...,\n",
      "          [-1.2103,  1.8037,  1.9920,  ...,  2.0777,  1.8550, -1.1760],\n",
      "          [-1.4672,  0.6049,  0.7933,  ...,  0.7933,  0.6049, -1.4672],\n",
      "          [-2.0323, -2.0152, -2.0152,  ..., -2.0494, -2.0665, -2.0665]],\n",
      "\n",
      "         [[-2.0007, -1.9482, -1.9657,  ..., -1.9657, -1.9832, -2.0182],\n",
      "          [-1.3880,  0.7479,  0.9580,  ...,  0.9755,  0.7479, -1.3704],\n",
      "          [-1.0903,  1.9909,  2.0434,  ...,  2.1310,  1.9909, -1.0903],\n",
      "          ...,\n",
      "          [-1.0728,  1.7983,  1.4132,  ...,  1.6408,  1.8683, -1.0728],\n",
      "          [-1.3529,  0.7654,  0.9405,  ...,  0.9580,  0.7654, -1.3704],\n",
      "          [-2.0007, -1.9482, -1.9657,  ..., -1.9657, -1.9657, -1.9832]],\n",
      "\n",
      "         [[-1.7696, -1.7173, -1.7347,  ..., -1.7347, -1.7347, -1.7870],\n",
      "          [-1.1596,  0.9668,  1.1934,  ...,  1.1934,  0.9668, -1.1421],\n",
      "          [-0.8633,  2.2043,  2.2740,  ...,  2.3611,  2.2217, -0.8633],\n",
      "          ...,\n",
      "          [-0.8633,  1.8905,  1.1237,  ...,  1.3328,  1.9428, -0.8458],\n",
      "          [-1.1770,  0.9319,  1.1411,  ...,  1.1585,  0.9668, -1.1421],\n",
      "          [-1.7347, -1.6824, -1.6999,  ..., -1.7347, -1.7347, -1.7522]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8893,  1.9064,  1.8722,  ...,  1.4269,  1.3927,  1.3755],\n",
      "          [ 1.8722,  1.8893,  1.8722,  ...,  1.4269,  1.4269,  1.4098],\n",
      "          [ 1.8722,  1.8722,  1.8550,  ...,  1.4440,  1.4269,  1.4098],\n",
      "          ...,\n",
      "          [-0.0116, -0.0116, -0.0287,  ..., -0.8849, -0.9534, -1.0219],\n",
      "          [-0.0629, -0.0629, -0.0801,  ..., -1.0562, -1.1418, -1.1075],\n",
      "          [-0.0972, -0.1314, -0.1657,  ..., -1.1760, -1.3302, -1.2788]],\n",
      "\n",
      "         [[ 2.0959,  2.0959,  2.0609,  ...,  1.5882,  1.5707,  1.5707],\n",
      "          [ 2.0959,  2.0959,  2.0609,  ...,  1.5882,  1.5532,  1.5532],\n",
      "          [ 2.0959,  2.0784,  2.0609,  ...,  1.5707,  1.5532,  1.5532],\n",
      "          ...,\n",
      "          [-0.4776, -0.4776, -0.4951,  ..., -0.1975, -0.2850, -0.3375],\n",
      "          [-0.5126, -0.5301, -0.5476,  ..., -0.3725, -0.4951, -0.4601],\n",
      "          [-0.5476, -0.6001, -0.6176,  ..., -0.5301, -0.8277, -0.7927]],\n",
      "\n",
      "         [[ 2.1694,  2.1694,  2.1346,  ...,  1.5768,  1.5594,  1.5245],\n",
      "          [ 2.1520,  2.1520,  2.1346,  ...,  1.5594,  1.5245,  1.5071],\n",
      "          [ 2.1520,  2.1520,  2.1346,  ...,  1.5245,  1.5071,  1.5071],\n",
      "          ...,\n",
      "          [-0.9156, -0.8981, -0.8807,  ..., -0.5147, -0.5844, -0.6541],\n",
      "          [-0.9156, -0.9156, -0.9156,  ..., -0.6890, -0.8110, -0.7761],\n",
      "          [-0.9330, -0.9504, -0.9678,  ..., -0.8633, -1.0898, -1.0376]]],\n",
      "\n",
      "\n",
      "        [[[-1.9980, -1.9980, -1.9980,  ..., -2.0665, -2.0665, -2.0665],\n",
      "          [-1.9638, -1.9467, -1.9467,  ..., -2.0665, -2.0665, -2.0665],\n",
      "          [-1.9809, -1.9638, -1.9467,  ..., -2.0665, -2.0665, -2.0665],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.6794, -0.6965, -0.7308],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.6623, -0.6965, -0.7308],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.6109, -0.6794, -0.6109]],\n",
      "\n",
      "         [[-2.0182, -2.0182, -2.0182,  ..., -1.9832, -1.9832, -1.9832],\n",
      "          [-1.9482, -1.9657, -1.9657,  ..., -1.9832, -1.9832, -1.9832],\n",
      "          [-1.9657, -1.9657, -1.9657,  ..., -1.9832, -1.9832, -1.9832],\n",
      "          ...,\n",
      "          [ 2.3235,  2.3235,  2.3235,  ..., -0.7402, -0.7577, -0.7927],\n",
      "          [ 2.3235,  2.3235,  2.3235,  ..., -0.7227, -0.7577, -0.7927],\n",
      "          [ 2.3235,  2.3235,  2.3235,  ..., -0.7402, -0.8102, -0.7402]],\n",
      "\n",
      "         [[-1.7870, -1.7870, -1.7870,  ..., -1.7522, -1.7522, -1.7522],\n",
      "          [-1.7347, -1.7347, -1.7347,  ..., -1.7522, -1.7522, -1.7522],\n",
      "          [-1.7522, -1.7347, -1.7347,  ..., -1.7522, -1.7522, -1.7522],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.6715, -0.6890, -0.7238],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.6541, -0.6890, -0.7238],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.6715, -0.7413, -0.6715]]]]), tensor([32, 10, 26, 25, 31, 33, 11,  7,  5, 22, 12, 12, 30, 17,  1, 23, 30, 25,\n",
      "        21,  0, 35, 28,  6,  1, 24, 27, 31, 16, 15,  7, 28, 21, 18, 25, 15, 29,\n",
      "        15, 13, 29, 13, 32,  4, 23, 10, 18, 25, 17, 28,  4,  5, 26, 30,  4, 33,\n",
      "        36,  8, 28, 12, 17, 20, 14, 14, 24, 14,  7, 11, 20, 31, 31, 30,  6,  6,\n",
      "        25, 12,  5,  5,  4, 27, 18, 28, 25,  6, 36, 20, 27, 21, 36, 24, 10,  0,\n",
      "         1, 23, 21,  5, 20, 10,  7,  8,  6,  2,  3, 11, 36, 22, 23, 28,  8, 30,\n",
      "         8, 25,  8, 30, 29,  6, 14, 26, 22, 19, 29, 10,  5,  2,  2,  9, 17, 12,\n",
      "        34, 27, 33, 30, 30, 18, 26, 34, 23, 28, 12, 17, 19,  1, 18, 34, 22, 26,\n",
      "        13, 22,  0, 33, 23,  0, 33, 29, 29,  1,  4, 15, 26, 25, 15, 10, 32, 23,\n",
      "         2, 34, 27, 10, 32,  0,  9, 11, 22, 22, 15, 10, 25, 20, 18, 28,  7, 21,\n",
      "        21, 26, 33, 16, 14, 28, 14, 27, 21,  3, 19, 35,  0, 31, 32, 33, 29, 22,\n",
      "         5, 18, 30, 31, 16, 13, 19, 24, 17, 36, 19,  8, 26, 32, 22, 13, 10, 29,\n",
      "         8,  4, 16, 30,  2, 28, 24, 10, 31,  4, 10, 18,  3, 35, 31, 33,  6, 27,\n",
      "        20, 11, 16, 23, 20,  0,  3, 27, 24, 30, 24, 19, 22, 31, 17, 35, 19,  4,\n",
      "        12, 13, 18, 33, 32,  9, 30,  9, 19,  1,  4,  3,  3, 25, 19,  7, 19, 30,\n",
      "        18, 26,  2,  0, 11,  0, 33, 31, 27, 36, 32, 35, 29, 25, 26,  3, 18, 14,\n",
      "        17, 28,  8,  0,  5, 16, 11,  4, 35, 29,  6,  3,  3, 21, 17, 11, 26, 17,\n",
      "        15, 33,  3,  6, 33,  8, 11, 10,  1, 18, 29, 13,  6,  2])]\n",
      "Inputs_u: tensor([[[[-0.6109, -0.5938, -0.5938,  ..., -0.3198, -0.3027, -0.3198],\n",
      "          [-0.5938, -0.5938, -0.5767,  ..., -0.3027, -0.3198, -0.3369],\n",
      "          [-0.6452, -0.6452, -0.6623,  ..., -0.3198, -0.3198, -0.3369],\n",
      "          ...,\n",
      "          [ 0.2282,  0.3481,  0.2453,  ...,  1.4269,  1.4954,  1.5125],\n",
      "          [ 0.2624,  0.2796,  0.1939,  ...,  1.4269,  1.4783,  1.5468],\n",
      "          [ 0.2453,  0.2111,  0.1426,  ...,  1.5468,  1.6324,  1.6324]],\n",
      "\n",
      "         [[-0.4076, -0.4076, -0.3901,  ..., -0.5651, -0.5826, -0.5826],\n",
      "          [-0.4601, -0.4426, -0.4251,  ..., -0.5476, -0.5651, -0.5826],\n",
      "          [-0.4951, -0.4951, -0.5126,  ..., -0.5651, -0.5651, -0.5826],\n",
      "          ...,\n",
      "          [ 0.2227,  0.3102,  0.1877,  ...,  1.5882,  1.6408,  1.6408],\n",
      "          [ 0.2402,  0.2402,  0.1527,  ...,  1.5882,  1.6583,  1.6933],\n",
      "          [ 0.2052,  0.1702,  0.1001,  ...,  1.7108,  1.7983,  1.7983]],\n",
      "\n",
      "         [[-0.1835, -0.1661, -0.1661,  ..., -0.8458, -0.8458, -0.8284],\n",
      "          [-0.2358, -0.2358, -0.2184,  ..., -0.8284, -0.8284, -0.8284],\n",
      "          [-0.2881, -0.2881, -0.3055,  ..., -0.8110, -0.8110, -0.8284],\n",
      "          ...,\n",
      "          [ 0.3393,  0.4788,  0.3742,  ...,  1.8208,  1.8557,  1.8731],\n",
      "          [ 0.3742,  0.4091,  0.3393,  ...,  1.8208,  1.8731,  1.9254],\n",
      "          [ 0.3742,  0.3568,  0.2871,  ...,  1.9603,  2.0474,  2.0474]]],\n",
      "\n",
      "\n",
      "        [[[-1.9980, -1.9980, -2.0323,  ...,  1.1529,  1.1529,  1.1700],\n",
      "          [-1.9980, -1.9980, -2.0323,  ...,  1.1529,  1.1529,  1.1529],\n",
      "          [-1.9980, -1.9980, -2.0323,  ...,  1.1700,  1.1529,  1.1529],\n",
      "          ...,\n",
      "          [-2.0494, -2.0494, -2.0494,  ..., -1.2445, -1.2617, -1.2788],\n",
      "          [-2.0665, -2.0494, -2.0494,  ..., -1.3130, -1.3130, -1.3473],\n",
      "          [-2.0837, -2.1179, -2.0837,  ..., -1.5185, -1.4843, -1.4500]],\n",
      "\n",
      "         [[-2.0182, -2.0007, -1.9832,  ...,  0.3452,  0.3452,  0.3627],\n",
      "          [-2.0182, -2.0007, -1.9832,  ...,  0.3452,  0.3452,  0.3452],\n",
      "          [-2.0182, -1.9832, -1.9832,  ...,  0.3277,  0.3102,  0.3102],\n",
      "          ...,\n",
      "          [-1.9657, -1.9657, -1.9657,  ..., -1.4580, -1.4755, -1.4930],\n",
      "          [-1.9832, -1.9657, -1.9657,  ..., -1.4755, -1.4755, -1.5105],\n",
      "          [-2.0007, -2.0357, -2.0007,  ..., -1.6331, -1.5980, -1.5630]],\n",
      "\n",
      "         [[-1.7870, -1.7522, -1.7347,  ..., -0.8633, -0.8633, -0.8458],\n",
      "          [-1.7696, -1.7347, -1.7347,  ..., -0.8633, -0.8633, -0.8633],\n",
      "          [-1.7522, -1.7347, -1.7347,  ..., -0.8633, -0.8807, -0.8807],\n",
      "          ...,\n",
      "          [-1.7347, -1.7347, -1.7347,  ..., -1.2641, -1.2816, -1.2990],\n",
      "          [-1.7522, -1.7347, -1.7347,  ..., -1.2990, -1.2990, -1.3339],\n",
      "          [-1.7696, -1.8044, -1.7696,  ..., -1.4036, -1.3687, -1.3339]]],\n",
      "\n",
      "\n",
      "        [[[-1.3644, -1.3987, -1.2959,  ..., -0.5253, -0.4739, -0.4911],\n",
      "          [-1.3302, -1.3644, -1.2788,  ..., -0.4739, -0.4226, -0.4568],\n",
      "          [-1.2788, -1.2788, -1.2445,  ..., -0.4397, -0.3541, -0.3369],\n",
      "          ...,\n",
      "          [-0.7137, -0.6794, -0.6281,  ...,  0.6392,  0.6906,  0.7591],\n",
      "          [-0.6794, -0.6281, -0.6452,  ...,  0.7077,  0.6734,  0.7248],\n",
      "          [-0.6623, -0.5424, -0.6281,  ...,  0.7762,  0.7419,  0.7591]],\n",
      "\n",
      "         [[-1.6155, -1.5805, -1.5455,  ..., -0.6352, -0.6176, -0.6176],\n",
      "          [-1.6331, -1.5630, -1.5630,  ..., -0.6001, -0.6352, -0.6352],\n",
      "          [-1.6681, -1.6331, -1.5805,  ..., -0.6527, -0.6352, -0.6352],\n",
      "          ...,\n",
      "          [-1.4230, -1.4580, -1.4055,  ..., -0.1800, -0.1450, -0.0924],\n",
      "          [-1.4580, -1.4930, -1.4230,  ..., -0.1800, -0.1800, -0.1450],\n",
      "          [-1.5280, -1.4930, -1.4230,  ..., -0.1625, -0.1275, -0.1099]],\n",
      "\n",
      "         [[-1.4907, -1.5430, -1.5256,  ..., -0.5670, -0.5844, -0.5844],\n",
      "          [-1.4733, -1.5256, -1.5430,  ..., -0.6367, -0.5844, -0.6018],\n",
      "          [-1.5081, -1.5430, -1.5430,  ..., -0.6193, -0.5495, -0.5321],\n",
      "          ...,\n",
      "          [-1.5779, -1.5953, -1.5430,  ..., -0.5321, -0.5321, -0.4798],\n",
      "          [-1.5953, -1.5953, -1.5604,  ..., -0.5670, -0.6193, -0.5844],\n",
      "          [-1.6476, -1.5604, -1.5779,  ..., -0.5147, -0.5495, -0.5321]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.0837, -2.0323, -2.0494,  ..., -2.0665, -2.0665, -2.1008],\n",
      "          [-1.4843,  0.6049,  0.8104,  ...,  0.8276,  0.6049, -1.4672],\n",
      "          [-1.1932,  1.8037,  1.8379,  ...,  1.8722,  1.8037, -1.1932],\n",
      "          ...,\n",
      "          [-1.2103,  1.8037,  1.9920,  ...,  2.0777,  1.8550, -1.1760],\n",
      "          [-1.4672,  0.6049,  0.7933,  ...,  0.7933,  0.6049, -1.4672],\n",
      "          [-2.0323, -2.0152, -2.0152,  ..., -2.0494, -2.0665, -2.0665]],\n",
      "\n",
      "         [[-2.0007, -1.9482, -1.9657,  ..., -1.9657, -1.9832, -2.0182],\n",
      "          [-1.3880,  0.7479,  0.9580,  ...,  0.9755,  0.7479, -1.3704],\n",
      "          [-1.0903,  1.9909,  2.0434,  ...,  2.1310,  1.9909, -1.0903],\n",
      "          ...,\n",
      "          [-1.0728,  1.7983,  1.4132,  ...,  1.6408,  1.8683, -1.0728],\n",
      "          [-1.3529,  0.7654,  0.9405,  ...,  0.9580,  0.7654, -1.3704],\n",
      "          [-2.0007, -1.9482, -1.9657,  ..., -1.9657, -1.9657, -1.9832]],\n",
      "\n",
      "         [[-1.7696, -1.7173, -1.7347,  ..., -1.7347, -1.7347, -1.7870],\n",
      "          [-1.1596,  0.9668,  1.1934,  ...,  1.1934,  0.9668, -1.1421],\n",
      "          [-0.8633,  2.2043,  2.2740,  ...,  2.3611,  2.2217, -0.8633],\n",
      "          ...,\n",
      "          [-0.8633,  1.8905,  1.1237,  ...,  1.3328,  1.9428, -0.8458],\n",
      "          [-1.1770,  0.9319,  1.1411,  ...,  1.1585,  0.9668, -1.1421],\n",
      "          [-1.7347, -1.6824, -1.6999,  ..., -1.7347, -1.7347, -1.7522]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8893,  1.9064,  1.8722,  ...,  1.4269,  1.3927,  1.3755],\n",
      "          [ 1.8722,  1.8893,  1.8722,  ...,  1.4269,  1.4269,  1.4098],\n",
      "          [ 1.8722,  1.8722,  1.8550,  ...,  1.4440,  1.4269,  1.4098],\n",
      "          ...,\n",
      "          [-0.0116, -0.0116, -0.0287,  ..., -0.8849, -0.9534, -1.0219],\n",
      "          [-0.0629, -0.0629, -0.0801,  ..., -1.0562, -1.1418, -1.1075],\n",
      "          [-0.0972, -0.1314, -0.1657,  ..., -1.1760, -1.3302, -1.2788]],\n",
      "\n",
      "         [[ 2.0959,  2.0959,  2.0609,  ...,  1.5882,  1.5707,  1.5707],\n",
      "          [ 2.0959,  2.0959,  2.0609,  ...,  1.5882,  1.5532,  1.5532],\n",
      "          [ 2.0959,  2.0784,  2.0609,  ...,  1.5707,  1.5532,  1.5532],\n",
      "          ...,\n",
      "          [-0.4776, -0.4776, -0.4951,  ..., -0.1975, -0.2850, -0.3375],\n",
      "          [-0.5126, -0.5301, -0.5476,  ..., -0.3725, -0.4951, -0.4601],\n",
      "          [-0.5476, -0.6001, -0.6176,  ..., -0.5301, -0.8277, -0.7927]],\n",
      "\n",
      "         [[ 2.1694,  2.1694,  2.1346,  ...,  1.5768,  1.5594,  1.5245],\n",
      "          [ 2.1520,  2.1520,  2.1346,  ...,  1.5594,  1.5245,  1.5071],\n",
      "          [ 2.1520,  2.1520,  2.1346,  ...,  1.5245,  1.5071,  1.5071],\n",
      "          ...,\n",
      "          [-0.9156, -0.8981, -0.8807,  ..., -0.5147, -0.5844, -0.6541],\n",
      "          [-0.9156, -0.9156, -0.9156,  ..., -0.6890, -0.8110, -0.7761],\n",
      "          [-0.9330, -0.9504, -0.9678,  ..., -0.8633, -1.0898, -1.0376]]],\n",
      "\n",
      "\n",
      "        [[[-1.9980, -1.9980, -1.9980,  ..., -2.0665, -2.0665, -2.0665],\n",
      "          [-1.9638, -1.9467, -1.9467,  ..., -2.0665, -2.0665, -2.0665],\n",
      "          [-1.9809, -1.9638, -1.9467,  ..., -2.0665, -2.0665, -2.0665],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.6794, -0.6965, -0.7308],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.6623, -0.6965, -0.7308],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.6109, -0.6794, -0.6109]],\n",
      "\n",
      "         [[-2.0182, -2.0182, -2.0182,  ..., -1.9832, -1.9832, -1.9832],\n",
      "          [-1.9482, -1.9657, -1.9657,  ..., -1.9832, -1.9832, -1.9832],\n",
      "          [-1.9657, -1.9657, -1.9657,  ..., -1.9832, -1.9832, -1.9832],\n",
      "          ...,\n",
      "          [ 2.3235,  2.3235,  2.3235,  ..., -0.7402, -0.7577, -0.7927],\n",
      "          [ 2.3235,  2.3235,  2.3235,  ..., -0.7227, -0.7577, -0.7927],\n",
      "          [ 2.3235,  2.3235,  2.3235,  ..., -0.7402, -0.8102, -0.7402]],\n",
      "\n",
      "         [[-1.7870, -1.7870, -1.7870,  ..., -1.7522, -1.7522, -1.7522],\n",
      "          [-1.7347, -1.7347, -1.7347,  ..., -1.7522, -1.7522, -1.7522],\n",
      "          [-1.7522, -1.7347, -1.7347,  ..., -1.7522, -1.7522, -1.7522],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.6715, -0.6890, -0.7238],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.6541, -0.6890, -0.7238],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.6715, -0.7413, -0.6715]]]])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[612], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m train_loss, train_supervised_loss, train_unsupervised_loss \u001b[38;5;241m=\u001b[39m train_fixmatch(\n\u001b[0;32m     40\u001b[0m     model, labeled_loader, unlabeled_loader, optimizer, device, epoch,\n\u001b[0;32m     41\u001b[0m     lambda_u\u001b[38;5;241m=\u001b[39mlambda_u, threshold\u001b[38;5;241m=\u001b[39mthreshold\n\u001b[0;32m     42\u001b[0m )\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Supervised: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_supervised_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Unsupervised: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_unsupervised_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[609], line 18\u001b[0m, in \u001b[0;36mtrain_fixmatch\u001b[1;34m(model, labeled_loader, unlabeled_loader, optimizer, device, epoch, lambda_u, threshold)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnlabeled batch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munlabeled_batch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs_u: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs_u\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m     inputs_u_w, inputs_u_s \u001b[38;5;241m=\u001b[39m inputs_u  \u001b[38;5;66;03m# Unpack weak and strong augmentations\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m     20\u001b[0m     unlabeled_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(unlabeled_loader)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "data_root = \"datasets\"\n",
    "target_types = 'category'\n",
    "num_classes = 37  # Pet dataset (all breeds)\n",
    "num_labels_per_class = 40  # Number of labeled samples per class\n",
    "image_size = 224\n",
    "batch_size_labeled = 64\n",
    "batch_size_unlabeled = 320  # 5x more than labeled, typical for FixMatch\n",
    "num_epochs = 10\n",
    "threshold = 0.95\n",
    "lambda_u = 1.0  # weight for unlabeled loss\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize Model\n",
    "model = Initialize_ResNet18(num_classes)  # 37 classes for pet breeds\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.03, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Data Loaders\n",
    "dataloaders = load_train_val_test_data(data_root, target_types, transform, num_labels_per_class, num_classes, batch_size_labeled, batch_size_unlabeled, image_size)\n",
    "labeled_loader = dataloaders['labeled']\n",
    "print(f\"Number of labeled samples: {len(labeled_loader.dataset)}\")\n",
    "print(f\"Number of unlabeled samples: {len(dataloaders['unlabeled'].dataset)}\")\n",
    "unlabeled_loader = dataloaders['unlabeled']\n",
    "validation_loader = dataloaders['val']\n",
    "test_loader = dataloaders['test']\n",
    "print(f\"Unlabeled loader batch size: {unlabeled_loader.batch_size}\")\n",
    "#labeled_loader = get_labeled_loader(batch_size=batch_size_labeled, image_size=image_size)\n",
    "#unlabeled_loader = get_unlabeled_loader(batch_size=batch_size_unlabeled, image_size=image_size)\n",
    "#validation_loader = get_validation_loader(batch_size=batch_size_labeled, image_size=image_size)\n",
    "\n",
    "# Training Loop\n",
    "best_top1 = 0.0\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"\\n--- Epoch {epoch}/{num_epochs} ---\")\n",
    "\n",
    "    # Train\n",
    "    train_loss, train_supervised_loss, train_unsupervised_loss = train_fixmatch(\n",
    "        model, labeled_loader, unlabeled_loader, optimizer, device, epoch,\n",
    "        lambda_u=lambda_u, threshold=threshold\n",
    "    )\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Supervised: {train_supervised_loss:.4f} | Unsupervised: {train_unsupervised_loss:.4f}\")\n",
    "\n",
    "    # Evaluate\n",
    "    val_top1, val_top5 = evaluate(model, validation_loader, device)\n",
    "\n",
    "    # Save best model\n",
    "    if val_top1 > best_top1:\n",
    "        best_top1 = val_top1\n",
    "        torch.save(model.state_dict(), \"best_fixmatch_model.pth\")\n",
    "        print(\"Saved new best model!\")\n",
    "    else:\n",
    "        print(\"No improvement, not saving model.\")        \n",
    "        \n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
